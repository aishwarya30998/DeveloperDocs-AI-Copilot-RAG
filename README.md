# ğŸ¤– Developer Docs Copilot

> Production-grade RAG system that answers questions using official techstack documentation (eg:fastapi)

[![Deployed on HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace%20Spaces-blue)](https://huggingface.co/spaces)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white)](https://www.docker.com/)
[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-3776AB?logo=python&logoColor=white)](https://www.python.org/)

## ğŸ¯ What This Project Demonstrates

This is a **production-style RAG (Retrieval-Augmented Generation)** system that showcases:

- âœ… **Professional documentation ingestion pipeline** with chunking strategies
- âœ… **Semantic search** using vector embeddings (ChromaDB)
- âœ… **Source attribution** with clickable citations
- âœ… **RAG evaluation metrics** (RAGAS framework)
- âœ… **Dockerized deployment** ready for cloud platforms
- âœ… **Production-grade error handling** and logging

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â”‚  Question   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Query Embedding                 â”‚
â”‚     (sentence-transformers)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Vector Search (ChromaDB)        â”‚
â”‚     - Top 5 relevant chunks         â”‚
â”‚     - Metadata: source, section     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Context Assembly                â”‚
â”‚     - Format chunks                 â”‚
â”‚     - Add instructions              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. LLM Generation (HF Inference)   â”‚
â”‚     - Answer with citations         â”‚
â”‚     - Code examples preserved       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Response + Source Links         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Local Setup

```bash
# Clone the repository
git clone https://github.com/aishwarya30998/DeveloperDocs-AI-Copilot-RAG.git
cd DeveloperDocs-AI-Copilot-RAG

# Create virtual environment
python -m venv venv
source venv/bin/activate
# On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt


# create .env and add your HF_TOKEN


# Run the application
python app.py
```

Visit `http://localhost:7860` in your browser.

## ğŸ“¦ Project Structure

```
fastapi-docs-copilot/
â”œâ”€â”€ app.py                      # Gradio UI application
â”œâ”€â”€ Dockerfile                  # Container configuration
â”œâ”€â”€ docker-compose.yml          # Local container orchestration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment variables template
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ chunking.py            # Document chunking strategies
â”‚   â”œâ”€â”€ embeddings.py          # Embedding generation
â”‚   â”œâ”€â”€ retriever.py           # Vector search logic
â”‚   â”œâ”€â”€ rag_pipeline.py        # Main RAG orchestration
â”‚   â””â”€â”€ prompts.py             # Prompt templates
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest_docs.py         # Documentation ingestion
â”‚   â”œâ”€â”€ evaluate_rag.py        # RAG metrics evaluation
â”‚   â””â”€â”€ test_retrieval.py      # Test retrieval quality
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Downloaded documentation
â”‚   â”œâ”€â”€ processed/             # Chunked documents
â”‚   â””â”€â”€ vectordb/              # ChromaDB storage
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_chunking.py
â”‚   â”œâ”€â”€ test_retriever.py
â”‚   â””â”€â”€ test_rag_pipeline.py
â”‚
â””â”€â”€ evals/
    â”œâ”€â”€ test_queries.json      # Evaluation dataset
    â””â”€â”€ results/               # Evaluation outputs
```

## ğŸ¯ Key Features

### 1. Smart Chunking

- **Semantic chunking** with overlap for context preservation
- **Metadata enrichment** (section titles, URLs, code blocks)
- **Configurable chunk sizes** (300-800 tokens)

### 2. Retrieval Quality

- **Hybrid search** (semantic + keyword)
- **Reranking** for improved relevance
- **Source attribution** with confidence scores

### 3. Answer Generation

- **Code-aware formatting** (preserves indentation)
- **Inline citations** with source links
- **Fallback handling** for low-confidence results

### 4. Production Features

- **Health check endpoint** (`/health`)
- **Query logging** for analytics
- **Rate limiting** (basic throttling)
- **Error recovery** with graceful degradation

## ğŸ“Š RAG Evaluation

We use **RAGAS** framework to measure:

| Metric                | Description                 | Target Score |
| --------------------- | --------------------------- | ------------ |
| **Faithfulness**      | Answer accuracy vs. context | > 0.8        |
| **Answer Relevancy**  | Response relevance to query | > 0.7        |
| **Context Precision** | Retrieval accuracy          | > 0.75       |
| **Context Recall**    | Context completeness        | > 0.8        |

Run evaluations:

```bash
python evaluate_rag.py
```

## ğŸ³ Docker Deployment

### Build and run locally:

```bash
docker build -t developerdocs-rag
docker run -p 7860:7860 --name developerdocs-rag-container developerdocs-rag
```

### Deploy to HuggingFace Spaces:

1. Create a new Space on HuggingFace
2. Enable Docker SDK
3. Push this repository
4. Add `HF_TOKEN` as a Space secret
5. Deploy automatically

## ğŸ§ª Testing

```bash
# Run all tests


# Test chunking strategy
pytest test_chunking.py -v

# Test retrieval quality
python test_retrieval.py
```

## ğŸ“ˆ Performance Benchmarks

On HuggingFace Spaces (free tier):

- **Query latency**: ~2-3 seconds
- **Vector DB size**: ~150MB (FastAPI docs)
- **Memory usage**: ~800MB
- **Concurrent users**: 5-10

## ğŸ› ï¸ Technology Stack

| Component      | Technology                               | Why?                               |
| -------------- | ---------------------------------------- | ---------------------------------- |
| **Embeddings** | `sentence-transformers/all-MiniLM-L6-v2` | Fast, lightweight, good quality    |
| **Vector DB**  | ChromaDB                                 | Easy setup, persistent storage     |
| **LLM**        | HuggingFace Inference API (Mistral-7B)   | Free tier, good code understanding |
| **Framework**  | LangChain                                | Industry standard, modular         |
| **UI**         | Gradio                                   | Rapid prototyping, HF integration  |
| **Deployment** | Docker + HF Spaces                       | Free, scalable, shareable          |

## ğŸ”® Future Enhancements

- [ ] Multi-documentation support (React, Django, etc.)
- [ ] Conversation memory for follow-up questions
- [ ] Advanced retrieval (HyDE, Multi-Query)
- [ ] User feedback loop for continuous improvement
- [ ] Analytics dashboard for query patterns

## ğŸ“ License

MIT License - feel free to use for your portfolio!

## ğŸ¤ Contributing

This is a portfolio project, but suggestions are welcome via issues.

## ğŸ“§ Contact

Built by Aishwarya as a portfolio demonstration of production RAG systems.

- Portfolio: https://aishwarya30998.github.io/projects.html
- LinkedIn: https://www.linkedin.com/in/aishwarya-pentyala/

---

â­ If this helped you understand production RAG, give it a star!
